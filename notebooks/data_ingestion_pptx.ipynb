{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import fitz\n",
    "from pptx import Presentation\n",
    "import requests\n",
    "import io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to download file from Google Drive\n",
    "def download_file_from_google_drive(url):\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()  # Ensure request was successful\n",
    "    return io.BytesIO(response.content)\n",
    "\n",
    "# Function to extract text from a PDF file\n",
    "def extract_text_from_pdf(pdf_content):\n",
    "    text_content = []\n",
    "    pdf_doc = fitz.open(stream=pdf_content, filetype=\"pdf\")\n",
    "    for page_num in range(pdf_doc.page_count):\n",
    "        page = pdf_doc[page_num]\n",
    "        text_content.append({\n",
    "            \"file_type\": \"PDF\",\n",
    "            \"page_or_slide\": page_num + 1,\n",
    "            \"content\": page.get_text()\n",
    "        })\n",
    "    pdf_doc.close()\n",
    "    return text_content\n",
    "\n",
    "# Function to extract text from a PowerPoint file\n",
    "def extract_text_from_pptx(pptx_content):\n",
    "    text_content = []\n",
    "    presentation = Presentation(pptx_content)\n",
    "    for slide_num, slide in enumerate(presentation.slides):\n",
    "        slide_text = \"\\n\".join(shape.text for shape in slide.shapes if hasattr(shape, \"text\"))\n",
    "        text_content.append({\n",
    "            \"file_type\": \"PPTX\",\n",
    "            \"page_or_slide\": slide_num + 1,\n",
    "            \"content\": slide_text\n",
    "        })\n",
    "    return text_content\n",
    "\n",
    "# Function to process files\n",
    "def process_files(file_urls):\n",
    "    extracted_data = []\n",
    "    for url in file_urls:\n",
    "        if url.endswith(\".pdf\"):\n",
    "            pdf_content = download_file_from_google_drive(url)\n",
    "            extracted_data.extend(extract_text_from_pdf(pdf_content))\n",
    "        elif url.endswith(\".pptx\"):\n",
    "            pptx_content = download_file_from_google_drive(url)\n",
    "            extracted_data.extend(extract_text_from_pptx(pptx_content))\n",
    "    return extracted_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file URLs\n",
    "file_urls = [\n",
    "    \"https://drive.google.com/uc?export=download&id=1umzTCsbBmuFx4xz9DSMI82oq21tHhbKL\",\n",
    "    \"https://drive.google.com/uc?export=download&id=13oqVt9LYdESPS8XNYFLhSLZMkZk52JXG\",\n",
    "    \"https://drive.google.com/uc?export=download&id=1Wib-VAY4TU-jwVykIu_Oi-6hpv0G-w7-\"\n",
    "]\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "output_dir = \"artifacts/data_ingestion\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Process files and save to CSV in the specified directory\n",
    "extracted_data = process_files(file_urls)\n",
    "df = pd.DataFrame(extracted_data)\n",
    "output_path = os.path.join(output_dir, \"extracted_data.csv\")\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Data extraction complete. Saved to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
