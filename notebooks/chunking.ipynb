{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunked PPTX data saved to /home/moraa/Documents/GenAI/Prompt_Engineering_for_E-Learning_Content_Creation/artifacts/chunked/chunked_pptx.json\n",
      "PPTX chunk metadata saved to /home/moraa/Documents/GenAI/Prompt_Engineering_for_E-Learning_Content_Creation/artifacts/chunked/metadata_chunked_pptx.json\n",
      "Chunked PDF data saved to /home/moraa/Documents/GenAI/Prompt_Engineering_for_E-Learning_Content_Creation/artifacts/chunked/chunked_pdf_1umzTCsbBmuFx4xz9DSMI82oq21tHhbKL.json\n",
      "PDF chunk metadata saved to /home/moraa/Documents/GenAI/Prompt_Engineering_for_E-Learning_Content_Creation/artifacts/chunked/metadata_chunked_pdf_1umzTCsbBmuFx4xz9DSMI82oq21tHhbKL.json\n",
      "Chunked PDF data saved to /home/moraa/Documents/GenAI/Prompt_Engineering_for_E-Learning_Content_Creation/artifacts/chunked/chunked_pdf_13oqVt9LYdESPS8XNYFLhSLZMkZk52JXG.json\n",
      "PDF chunk metadata saved to /home/moraa/Documents/GenAI/Prompt_Engineering_for_E-Learning_Content_Creation/artifacts/chunked/metadata_chunked_pdf_13oqVt9LYdESPS8XNYFLhSLZMkZk52JXG.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Specify the root directory for the artifacts\n",
    "root_dir = '/home/moraa/Documents/GenAI/Prompt_Engineering_for_E-Learning_Content_Creation'\n",
    "\n",
    "# Paths to your extracted data JSON files\n",
    "pptx_json_path = os.path.join(root_dir, 'artifacts/data_ingestion_pptx/extracted_data.json')\n",
    "pdf_json_paths = [\n",
    "    os.path.join(root_dir, 'artifacts/ingest_pdf/extracted_data_1umzTCsbBmuFx4xz9DSMI82oq21tHhbKL.json'),\n",
    "    os.path.join(root_dir, 'artifacts/ingest_pdf/extracted_data_13oqVt9LYdESPS8XNYFLhSLZMkZk52JXG.json')\n",
    "]\n",
    "\n",
    "# Chunking parameters\n",
    "CHUNK_SIZE = 200  # Number of characters per chunk\n",
    "\n",
    "# Function to load JSON data\n",
    "def load_json_data(json_path):\n",
    "    with open(json_path, 'r') as json_file:\n",
    "        return json.load(json_file)\n",
    "\n",
    "# Function to create chunks\n",
    "def create_chunks(text, chunk_size):\n",
    "    # Split text into chunks of specified size\n",
    "    return [text[i:i + chunk_size] for i in range(0, len(text), chunk_size)]\n",
    "\n",
    "# Function to create chunk metadata\n",
    "def create_chunk_metadata(source_file, chunked_data):\n",
    "    metadata = {\n",
    "        \"source_file\": source_file,\n",
    "        \"chunking_date\": str(datetime.datetime.now()),\n",
    "        \"number_of_chunks\": len(chunked_data),\n",
    "        \"details\": []\n",
    "    }\n",
    "\n",
    "    for idx, chunk in enumerate(chunked_data):\n",
    "        metadata['details'].append({\n",
    "            \"chunk_index\": idx,\n",
    "            \"chunk_length\": len(chunk)\n",
    "        })\n",
    "\n",
    "    return metadata\n",
    "\n",
    "# Specify the folder for chunked data\n",
    "chunked_folder = os.path.join(root_dir, 'artifacts/chunked')\n",
    "os.makedirs(chunked_folder, exist_ok=True)\n",
    "\n",
    "# Process PPTX data\n",
    "pptx_data = load_json_data(pptx_json_path)\n",
    "pptx_text = \" \".join([item.get('text', '') for item in pptx_data])\n",
    "pptx_chunks = create_chunks(pptx_text, CHUNK_SIZE)\n",
    "\n",
    "# Save chunked PPTX data and metadata\n",
    "pptx_chunked_path = os.path.join(chunked_folder, 'chunked_pptx.json')\n",
    "with open(pptx_chunked_path, 'w') as chunked_file:\n",
    "    json.dump(pptx_chunks, chunked_file, indent=4)\n",
    "\n",
    "pptx_metadata = create_chunk_metadata('downloaded_presentation.pptx', pptx_chunks)\n",
    "pptx_metadata_path = os.path.join(chunked_folder, 'metadata_chunked_pptx.json')\n",
    "with open(pptx_metadata_path, 'w') as metadata_file:\n",
    "    json.dump(pptx_metadata, metadata_file, indent=4)\n",
    "\n",
    "print(f\"Chunked PPTX data saved to {pptx_chunked_path}\")\n",
    "print(f\"PPTX chunk metadata saved to {pptx_metadata_path}\")\n",
    "\n",
    "# Process PDF data\n",
    "for pdf_json_path in pdf_json_paths:\n",
    "    pdf_data = load_json_data(pdf_json_path)\n",
    "    pdf_text = \" \".join([item.get('text', '') for item in pdf_data])\n",
    "    pdf_chunks = create_chunks(pdf_text, CHUNK_SIZE)\n",
    "\n",
    "    # Save chunked PDF data and metadata\n",
    "    pdf_filename = os.path.basename(pdf_json_path).replace('extracted_data_', '').replace('.json', '')\n",
    "    pdf_chunked_path = os.path.join(chunked_folder, f'chunked_pdf_{pdf_filename}.json')\n",
    "    with open(pdf_chunked_path, 'w') as chunked_file:\n",
    "        json.dump(pdf_chunks, chunked_file, indent=4)\n",
    "\n",
    "    pdf_metadata = create_chunk_metadata(pdf_filename, pdf_chunks)\n",
    "    pdf_metadata_path = os.path.join(chunked_folder, f'metadata_chunked_pdf_{pdf_filename}.json')\n",
    "    with open(pdf_metadata_path, 'w') as metadata_file:\n",
    "        json.dump(pdf_metadata, metadata_file, indent=4)\n",
    "\n",
    "    print(f\"Chunked PDF data saved to {pdf_chunked_path}\")\n",
    "    print(f\"PDF chunk metadata saved to {pdf_metadata_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
